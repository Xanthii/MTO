{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse.py\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_array\n",
    "# ========================\n",
    "# === Public functions ===\n",
    "# ========================\n",
    "def tpd_file2dict(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        s = f.read()\n",
    "    d = _parse(s)\n",
    "    # _checkparams(d)\n",
    "    return d\n",
    "# =====================================\n",
    "# === Private functions and helpers ===\n",
    "# =====================================\n",
    "def _parse(s):\n",
    "    snew = s.splitlines()\n",
    "    snew = [line.split('#')[0] for line in snew] # Get rid of all comments\n",
    "    snew = [line.replace('\\t', '') for line in snew]\n",
    "    snew = [line.replace(' ', '') for line in snew]\n",
    "    snew = list(filter(len, snew))\n",
    "\n",
    "    d = dict([line.split(':') for line in snew]) \n",
    "    return _parse_dict(d)\n",
    " \n",
    "\n",
    "def _parse_dict(d):\n",
    "       # Read/convert minimum required input and convert, else exit:\n",
    "    d = d.copy()\n",
    "    try:\n",
    "        d['PROB_TYPE'] = d['PROB_TYPE'].lower()\n",
    "        d['VOL_FRAC'] = float(d['VOL_FRAC'])\n",
    "        d['FILT_RAD'] = float(d['FILT_RAD'])\n",
    "        d['P_FAC'] = float(d['P_FAC'])\n",
    "        d['NUM_ELEM_X'] = int(d['NUM_ELEM_X'])\n",
    "        d['NUM_ELEM_Y'] = int(d['NUM_ELEM_Y'])\n",
    "        d['NUM_ELEM_Z'] = int(d['NUM_ELEM_Z'])\n",
    "        d['DOF_PN'] = int(d['DOF_PN'])\n",
    "        d['ETA'] = str(d['ETA']).lower()\n",
    "\n",
    "    except:\n",
    "        raise ValueError('One or more parameters incorrectly specified.')\n",
    "\n",
    "    # Check for number of iterations or change stop value:\n",
    "    try:\n",
    "        d['NUM_ITER'] = int(d['NUM_ITER'])\n",
    "    except KeyError:\n",
    "        try:\n",
    "            d['CHG_STOP'] = float(d['CHG_STOP'])\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Neither NUM_ITER nor CHG_STOP was declared\")\n",
    "\n",
    "    # Check for GSF penalty factor:\n",
    "    try:\n",
    "        d['Q_FAC'] = float(d['Q_FAC'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # Check for continuation parameters:\n",
    "    try:\n",
    "        d['P_MAX'] = float(d['P_MAX'])\n",
    "        d['P_HOLD'] = int(d['P_HOLD'])\n",
    "        d['P_INCR'] = float(d['P_INCR'])\n",
    "        d['P_CON'] = float(d['P_CON'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        d['Q_MAX'] = float(d['Q_MAX'])\n",
    "        d['Q_HOLD'] = int(d['Q_HOLD'])\n",
    "        d['Q_INCR'] = float(d['Q_INCR'])\n",
    "        d['Q_CON'] = float(d['Q_CON'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # Check for active elements:\n",
    "    try:\n",
    "        d['ACTV_ELEM'] = _tpd2vec(d['ACTV_ELEM'], int) - 1\n",
    "    except KeyError:\n",
    "        d['ACTV_ELEM'] = _tpd2vec('', int)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # Check for passive elements:\n",
    "    try:\n",
    "        d['PASV_ELEM'] = _tpd2vec(d['PASV_ELEM'], int) - 1\n",
    "    except KeyError:\n",
    "        d['PASV_ELEM'] = _tpd2vec('', int)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # Check if diagonal quadratic approximation is required:\n",
    "    try:\n",
    "        d['APPROX'] = d['APPROX'].lower()\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # How to do the following compactly (perhaps loop through keys)? Check for\n",
    "    # keys and create fixed DOF vector, loaded DOF vector and load values\n",
    "    # vector.\n",
    "    dofpn = d['DOF_PN']\n",
    "\n",
    "    x = d.get('FXTR_NODE_X', '')\n",
    "    y = d.get('FXTR_NODE_Y', '')\n",
    "    z = d.get('FXTR_NODE_Z', '')\n",
    "    d['FIX_DOF'] = _dofvec(x, y, z, dofpn)\n",
    "\n",
    "    x = d.get('LOAD_NODE_X', '')\n",
    "    y = d.get('LOAD_NODE_Y', '')\n",
    "    z = d.get('LOAD_NODE_Z', '')\n",
    "    d['LOAD_DOF'] = _dofvec(x, y, z, dofpn)\n",
    "\n",
    "    x = d.get('LOAD_VALU_X', '')\n",
    "    y = d.get('LOAD_VALU_Y', '')\n",
    "    z = d.get('LOAD_VALU_Z', '')\n",
    "    d['LOAD_VAL'] = _valvec(x, y, z)\n",
    "\n",
    "    x = d.get('LOAD_NODE_X_OUT', '')\n",
    "    y = d.get('LOAD_NODE_Y_OUT', '')\n",
    "    z = d.get('LOAD_NODE_Z_OUT', '')\n",
    "    d['LOAD_DOF_OUT'] = _dofvec(x, y, z, dofpn)\n",
    "\n",
    "    x = d.get('LOAD_VALU_X_OUT', '')\n",
    "    y = d.get('LOAD_VALU_Y_OUT', '')\n",
    "    z = d.get('LOAD_VALU_Z_OUT', '')\n",
    "    d['LOAD_VAL_OUT'] = _valvec(x, y, z)\n",
    "\n",
    "\n",
    "    # The following entries are created and added to the dictionary,\n",
    "    # they are not specified in the ToPy problem definition file:\n",
    "    Ksize = d['DOF_PN'] * (d['NUM_ELEM_X'] + 1) * (d['NUM_ELEM_Y'] + 1) * \\\n",
    "    (d['NUM_ELEM_Z'] + 1) #  Memory allocation hint for PySparse\n",
    "    d['K'] = coo_array((Ksize, Ksize)) #  Global stiffness matrix\n",
    "    d['E2SDOFMAPI'] =  _e2sdofmapinit(d['NUM_ELEM_X'], d['NUM_ELEM_Y'], \\\n",
    "    d['DOF_PN']) #  Initial element to structure DOF mapping\n",
    "\n",
    "    return d\n",
    "\n",
    "def _tpd2vec(seq, dtype=float):\n",
    "    \"\"\"\n",
    "    Convert a tpd file string to a vector, return a NumPy array.\n",
    "\n",
    "    EXAMPLES:\n",
    "        >>> _tpd2vec('1|13|4; 20; 25|28')\n",
    "        array([  1.,   5.,   9.,  13.,  20.,  25.,  26.,  27.,  28.])\n",
    "        >>> _tpd2vec('5.5; 1.2@3; 3|7|2')\n",
    "        array([ 5.5,  1.2,  1.2,  1.2,  3. ,  5. ,  7. ])\n",
    "        >>> _tpd2vec(' ')\n",
    "        array([], dtype=float64)\n",
    "\n",
    "    \"\"\"\n",
    "    finalvec = np.array([], dtype)\n",
    "    for s in seq.split(';'):\n",
    "        if s.count('|'):\n",
    "            values = [dtype(v) for v in s.split('|')]\n",
    "            values[1] += 1\n",
    "            vec = np.arange(*values)\n",
    "        elif s.count('@'):\n",
    "            value, num = s.split('@')\n",
    "            try:\n",
    "                vec = np.ones(int(num)) * dtype(value)\n",
    "            except ValueError:\n",
    "                raise ValueError('%s is incorrectly specified' % seq)\n",
    "        else:\n",
    "            try:\n",
    "                vec = [dtype(s)]\n",
    "            except ValueError:\n",
    "                vec = np.array([], dtype)\n",
    "        finalvec = np.append(finalvec, vec)\n",
    "    return finalvec\n",
    "\n",
    "def _dofvec(x, y, z, dofpn):\n",
    "    \"\"\"\n",
    "    DOF vector.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vec_x = _tpd2vec(x)\n",
    "    except AttributeError:\n",
    "        vec_x = np.array(x)\n",
    "\n",
    "    try:\n",
    "        vec_y = _tpd2vec(y)\n",
    "    except AttributeError:\n",
    "        vec_y = np.array(y)\n",
    "\n",
    "    try:\n",
    "        vec_z = _tpd2vec(z)\n",
    "    except AttributeError:\n",
    "        vec_z = np.array(z)\n",
    "\n",
    "    dofx = (vec_x - 1) * dofpn\n",
    "    dofy = (vec_y - 1) * dofpn + 1\n",
    "    if dofpn == 2:\n",
    "        dofz = []\n",
    "    else:\n",
    "        dofz = (vec_z - 1) * dofpn + 2\n",
    "    return np.r_[dofx, dofy, dofz].astype(int)\n",
    "\n",
    "def _valvec(x, y, z):\n",
    "    \"\"\"\n",
    "    Values (e.g., of loads) vector.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vec_x = _tpd2vec(x)\n",
    "    except AttributeError:\n",
    "        vec_x = x\n",
    "\n",
    "    try:\n",
    "        vec_y = _tpd2vec(y)\n",
    "    except AttributeError:\n",
    "        vec_y = y\n",
    "\n",
    "    if z:\n",
    "        try:\n",
    "            vec_z = _tpd2vec(z)\n",
    "        except AttributeError:\n",
    "            vec_z = z\n",
    "    else:\n",
    "        vec_z = []\n",
    "\n",
    "    return np.r_[vec_x, vec_y, vec_z]\n",
    "\n",
    "def _e2sdofmapinit(nelx, nely, dofpn):\n",
    "    \"\"\"\n",
    "    Create the initial element to structure (e2s) DOF mapping (connectivity).\n",
    "    Return a vector as a NumPy array.\n",
    "\n",
    "    \"\"\"\n",
    "    if dofpn == 1:\n",
    "        e2s = np.r_[1, (nely + 2), (nely + 1), 0]\n",
    "        e2s = np.r_[e2s, (e2s + (nelx + 1) * (nely + 1))]\n",
    "    elif dofpn == 2:\n",
    "        b = np.arange(2 * (nely + 1), 2 * (nely + 1) + 2)\n",
    "        a = b + 2\n",
    "        e2s = np.r_[2, 3, a, b, 0, 1]\n",
    "    elif dofpn == 3:\n",
    "        d = np.arange(3)\n",
    "        a = d + 3\n",
    "        c = np.arange(3 * (nely + 1), 3 * (nely + 1) + 3)\n",
    "        b = np.arange(3 * (nely + 2), 3 * (nely + 2) + 3)\n",
    "        h = np.arange(3 * (nelx + 1) * (nely + 1), 3 * (nelx + 1) * (nely + 1) + 3)\n",
    "        e = np.arange(3 * ((nelx+1) * (nely+1)+1), 3 * ((nelx+1) * (nely+1)+1) + 3)\n",
    "        g = np.arange(3 * ((nelx + 1) * (nely + 1) + (nely + 1)),\\\n",
    "            3 * ((nelx + 1) * (nely + 1) + (nely + 1)) + 3)\n",
    "        f = np.arange(3 * ((nelx + 1) * (nely + 1) + (nely + 2)),\\\n",
    "            3 * ((nelx + 1) * (nely + 1) + (nely + 2)) + 3)\n",
    "        e2s = np.r_[a, b, c, d, e, f, g, h]\n",
    "    return e2s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topology.py\n",
    "# from parser import tpd_file2dict\n",
    "MAX_ITERS = 250\n",
    "\n",
    "SOLID, VOID = 1.000, 0.001 #  Upper and lower bound value for design variables\n",
    "KDATUM = 0.1 #  Reference stiffness value of springs for mechanism synthesis\n",
    "\n",
    "# Constants for exponential approximation:\n",
    "A_LOW = -3 #  Lower restriction on 'a' for exponential approximation\n",
    "A_UPP = -1e-5 #  Upper restriction on 'a' for exponential approximation\n",
    "\n",
    "class Topology:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    # ======================\n",
    "    # === Public methods ===\n",
    "    # ======================\n",
    "    def load_tpd_file(self, fname):\n",
    "        self.tpdfname = fname \n",
    "        self.topydict = tpd_file2dict(fname)\n",
    "\n",
    "    def set_top_params(self):\n",
    "        '''\n",
    "        firstly, consider the general 3d case\n",
    "        '''\n",
    "        if not self.topydict:\n",
    "            raise Exception('You must first load a TPD file!')\n",
    "        self.probtype = self.topydict['PROB_TYPE'] #  Problem type\n",
    "        self.probname = self.topydict.get('PROB_NAME', '') #  Problem name\n",
    "        self.volfrac = self.topydict['VOL_FRAC'] #  Volume fraction\n",
    "        self.filtrad = self.topydict['FILT_RAD'] #  Filter radius\n",
    "        self.p = self.topydict['P_FAC'] #  'Standard' penalisation factor\n",
    "        self.dofpn = self.topydict['DOF_PN'] #  DOF per node\n",
    "        self.e2sdofmapi = self.topydict['E2SDOFMAPI'] #  Elem to structdof map\n",
    "        self.nelx = self.topydict['NUM_ELEM_X'] #  Number of elements in X\n",
    "        self.nely = self.topydict['NUM_ELEM_Y'] #  Number of elements in Y\n",
    "        self.nelz = self.topydict['NUM_ELEM_Z'] #  Number of elements in Z\n",
    "        self.fixdof = self.topydict['FIX_DOF'] #  Fixed dof vector\n",
    "        self.loaddof = self.topydict['LOAD_DOF'] #  Loaded dof vector\n",
    "        self.loadval = self.topydict['LOAD_VAL'] #  Loaded dof values\n",
    "        # self.Ke = self.topydict['ELEM_K'] #  Element stiffness matrix\n",
    "        self.K = self.topydict['K'] #  Global stiffness matrix\n",
    "\n",
    "        # Check for either one of the following two, will take NUM_ITER if both\n",
    "        # are specified.\n",
    "        try:\n",
    "            self.numiter = self.topydict['NUM_ITER'] #  Number of iterations\n",
    "            \n",
    "        except KeyError:\n",
    "            self.chgstop = self.topydict['CHG_STOP'] #  Change stop criteria\n",
    "            self.numiter = MAX_ITERS\n",
    "\n",
    "        # All DOF vector and design variables arrays:\n",
    "        if self.dofpn == 1:\n",
    "            if self.nelz == 0: #  *had to this\n",
    "                self.e2sdofmapi = self.e2sdofmapi[0:4]\n",
    "                self.alldof = np.arange(self.dofpn * (self.nelx + 1) * \\\n",
    "                    (self.nely + 1))\n",
    "                self.desvars = np.zeros((self.nely, self.nelx)) + self.volfrac\n",
    "            else:\n",
    "                self.alldof = np.arange(self.dofpn * (self.nelx + 1) * \\\n",
    "                    (self.nely + 1) * (self.nelz + 1))\n",
    "                self.desvars = np.zeros((self.nelz, self.nely, self.nelx)) + \\\n",
    "                    self.volfrac\n",
    "        elif self.dofpn == 2:\n",
    "            self.alldof = np.arange(self.dofpn * (self.nelx + 1) * (self.nely + 1))\n",
    "            self.desvars = np.zeros((self.nely, self.nelx)) + self.volfrac\n",
    "        else:\n",
    "            self.alldof = np.arange(self.dofpn * (self.nelx + 1) *\\\n",
    "                (self.nely + 1) * (self.nelz + 1))\n",
    "            self.desvars = np.zeros((self.nelz, self.nely, self.nelx)) + \\\n",
    "                self.volfrac\n",
    "\n",
    "        self.df = np.zeros_like(self.desvars) #  Derivatives of obj. func. (array)\n",
    "        self.freedof = np.setdiff1d(self.alldof, self.fixdof) #  Free DOF vector\n",
    "        self.r = np.zeros_like(self.alldof).astype(float) #  Load vector\n",
    "        self.r[self.loaddof] = self.loadval #  Assign load values at loaded dof\n",
    "        self.rfree = self.r[self.freedof] #  Modified load vector (free dof)\n",
    "        self.d = np.zeros_like(self.r) #  Displacement vector\n",
    "        self.dfree = np.zeros_like(self.rfree) #  Modified load vector (free dof)\n",
    "        # Determine which rows and columns must be deleted from global K:\n",
    "        self._rcfixed = np.where(np.in1d(self.alldof, self.fixdof), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fea(self):pass\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise(topology):\n",
    "# Optimising function:\n",
    "    def _optimise(t):\n",
    "        t.fea()\n",
    "        t.sens_analysis()\n",
    "        t.filter_sens_sigmund()\n",
    "        t.update_desvars_oc()\n",
    "    try:\n",
    "        while topology.change > topology.chgstop:\n",
    "            _optimise(topology)\n",
    "    except AttributeError:\n",
    "        for i in range(topology.numiter):\n",
    "            _optimise(topology)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Topology()\n",
    "t.load_tpd_file('mmb_beam_2d_reci.tpd')\n",
    "t.set_top_params()\n",
    "print(t.alldof)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6a892c11cf255743e3b4b0e2e867f98af2555f2c81ef2504e9333fe48f5d005"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
